{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import module (library)\n",
    "\n",
    "import pandas as pd\n",
    "import pycaret\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from pycaret.regression import *\n",
    "\n",
    "from pycaret.regression import load_model\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe_connected'\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import module (user defined function)\n",
    "\n",
    "from py_module.load_data import load_data\n",
    "from py_module.plot_data import plot_histogram\n",
    "from py_module.regression import regression_basic\n",
    "from py_module.pre_processing import *\n",
    "from py_module.verify import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === import raw_data (from csv file) ===\n",
    "\n",
    "filename = \"./Data_2021_10_14_v1 (N98923)/Data.csv\" # csv file directory and name\n",
    "\n",
    "raw_data = load_data(fn=filename, pp=1)\n",
    "\n",
    "\n",
    "## === dataset pre-processing ===\n",
    "\n",
    "# drop output data except for target output\n",
    "\n",
    "parameter = \"Lmt\" # target output pamareter\n",
    "processed_data = drop_output(raw_data, parameter)\n",
    "\n",
    "\n",
    "\n",
    "# cut data\n",
    "## - opt\n",
    "# lo : lower bound value (default : -inf)\n",
    "# hi : upper bound value (default : inf)\n",
    "\n",
    "processed_data = cut_data(processed_data, parameter=\"Lmt\", lo=0.1, hi=10)\n",
    "\n",
    "\n",
    "\n",
    "# add feature\n",
    "# 기존에 존재하는 input parameter들을 이용해서 물리적인 의미를 갖는 새로운 파라미터를 만들어 낼 시 모델의 성능을 증가시킬 수 있음\n",
    "# ex> 변압기 자화 인덕턴스는 턴수의 제곱에 비례하므로 턴수의 제곱에 해당하는 파라미터를 새로 만들어 자화인덕터 regression 모델을 만들 경우 모델 성능 증가\n",
    "\n",
    "new_feature_names = [\"N1s\"]\n",
    "\n",
    "processed_data = add_feature(processed_data, parameter, new_feature_names = new_feature_names)\n",
    "\n",
    "\n",
    "\n",
    "processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === compare algorithm ===\n",
    "# 여러 regression 알고리즘 중 가장 높은 성능을 내는 알고리즘 탐색 (모든 알고리즘 탐색)\n",
    "\n",
    "# activate logger\n",
    "[model, data_seen, data_unseen] = regression_basic(processed_data, parameter, algorithm=\"lightgbm\", frac_ratio=0.9, save_en=False, save_model_name=\"model\", new_feature_names=new_feature_names)\n",
    "\n",
    "\n",
    "# variable\n",
    "algorithm_list = models().index\n",
    "except_list = [\"kr\",\"svm\"] # algorithm list to exclude from train\n",
    "result = []\n",
    "\n",
    "\n",
    "# eleminate algorithm in exception list\n",
    "for al_name in except_list :\n",
    "\n",
    "    algorithm_list = algorithm_list[algorithm_list!=al_name]\n",
    "\n",
    "    \n",
    "# train each algorithm\n",
    "for al_name in algorithm_list :\n",
    "\n",
    "    [model, data_seen, data_unseen] = regression_basic(processed_data, parameter, algorithm=al_name, new_feature_names=new_feature_names)\n",
    "    [R2, MAE, MSE, RMSE, MPE] = verify_model(model, data_seen, data_unseen, parameter)\n",
    "    result.append([al_name, R2, MAE, MSE, RMSE, MPE])\n",
    "\n",
    "\n",
    "# compare model result\n",
    "pd.DataFrame(result,columns = [\"algorithm\",\"R2\",\"MAE\",\"MSE\",\"RMSE\",\"MPE(%)\"]).sort_values(by='R2' ,ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare algorithm (tuned case)\n",
    "# 여러 regression 알고리즘 중 가장 높은 성능을 내는 알고리즘 탐색 (모든 알고리즘 탐색)\n",
    "# 각각의 algorithm은 auto tune을 이용하여 튜닝\n",
    "\n",
    "# activate logger\n",
    "[model, data_seen, data_unseen] = regression_basic(processed_data, parameter, algorithm=\"lightgbm\", frac_ratio=0.9, save_en=False, save_model_name=\"model\", new_feature_names=new_feature_names)\n",
    "\n",
    "\n",
    "# variable\n",
    "algorithm_list = models().index\n",
    "except_list = [\"kr\",\"svm\"] # algorithm list to exclude from train\n",
    "result = []\n",
    "\n",
    "\n",
    "# eleminate algorithm in exception list\n",
    "for al_name in except_list :\n",
    "\n",
    "    algorithm_list = algorithm_list[algorithm_list!=al_name]\n",
    "\n",
    "    \n",
    "# train each algorithm\n",
    "for al_name in algorithm_list :\n",
    "\n",
    "    [model, data_seen, data_unseen] = regression_basic(processed_data, parameter, algorithm=al_name, new_feature_names=new_feature_names)\n",
    "    tuned_model = tune_model(model, n_iter=100, optimize=\"MAE\", early_stopping=False, choose_better=True, verbose=True)\n",
    "    [R2, MAE, MSE, RMSE, MPE] = verify_model(tuned_model, data_seen, data_unseen, parameter)\n",
    "    result.append([al_name, R2, MAE, MSE, RMSE, MPE])\n",
    "\n",
    "\n",
    "# compare model result\n",
    "pd.DataFrame(result,columns = [\"algorithm\",\"R2\",\"MAE\",\"MSE\",\"RMSE\",\"MPE(%)\"]).sort_values(by='R2' ,ascending=False).reset_index(drop=True)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3bc87a6c1baa762acb2432f23bd8ebde523bb30795feb16e4094925d47a86dcf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('NEC_Stable': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
